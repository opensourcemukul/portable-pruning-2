# ğŸ”§ Portable Pruning

**Data-Free. Device-Agnostic. Simple CNN Pruning for Edge Devices.**

This is a modular and clean framework to help you experiment with pruning deep learning models like `ResNet18`, `ResNet34`, and `MobileNetV2`. The best part â€” you donâ€™t need any training data for pruning. Itâ€™s built for people who want to deploy compressed models on edge devices like Raspberry Pi, Jetson Nano, or Android phones.

---

## ğŸ” What it Can Do

- âœ… Works without any training data  
- ğŸ§± Device-agnostic â€” models run on various edge hardware  
- ğŸ”„ Easy-to-plug pruning strategies  
- ğŸ“ Measures: FLOPs, Params, Latency, RAM, Accuracy  
- ğŸ“¤ Exports `.pth` and `.onnx` for deployment  
- ğŸ“Š Logs every experiment in a CSV automatically  

---

## âš™ï¸ Installation & Setup

### ğŸ”¹ Step 1: Clone the Repo

```bash
git clone https://github.com/yourusername/portable-pruning.git
cd portable-pruning
```

### ğŸ”¹ Step 2: Install Requirements

```bash
pip install -r requirements.txt
```

If you have issues with importing the `portable_pruning` module, add it to your path:

```bash
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### ğŸ”¹ Step 3: Dataset

By default, the code uses `imagenette2-320`. You donâ€™t need to train anything â€” just prune and evaluate.

---

## ğŸ§  Models Available

- `resnet18` â€” lightweight and fast  
- `resnet34` â€” deeper but still efficient  
- `mobilenet_v2` â€” made for mobile deployment  

All are from `torchvision.models` and come pretrained.

---

## âœ‚ï¸ Pruning Methods

| Method      | Description |
|-------------|-------------|
| `l1`        | Unstructured pruning (L1 norm) |
| `batchnorm` | Based on BatchNorm gamma values |
| `red`       | Redundancy-based with KDE (`alpha`, `tau`) |
| `redpp`     | Lighter version of RED |
| `builtin`   | PyTorchâ€™s pruning API |
| `autodfp`   | RL-based (Auto Deep Filter Pruning) |

---

## ğŸ§° Pruning Modes (For `builtin` Method Only)

Here are the four available pruning modes (used with the `builtin` method):

- `l1_unstructured` â€“ Removes individual weights with the lowest L1 norm.
- `ln_structured` â€“ Drops entire filters or channels using structured norms.
- `random_structured` â€“ Randomly removes full structures (like channels).
- `random_unstructured` â€“ Randomly removes individual weights.

Use these based on whether you want structured sparsity (good for speed-up) or unstructured sparsity (good for compression).

---

## ğŸš€ Run It (Your Way)

### ğŸ”¸ Prune a Model

```bash
python run_pruning.py   --model resnet18   --method builtin   --mode l1_unstructured   --compression 0.5   --onnx   --output_dir .outputs/my_run
```

### ğŸ”¸ Just Evaluate Baseline (No Pruning)

```bash
python run_pruning.py   --model resnet18   --method builtin   --mode l1_unstructured   --compression 0.5   --baseline   --onnx   --output_dir .outputs/my_run
```

---

## ğŸ§ª Run a Full Experiment Grid

```bash
python experiment.py --subset_size 100 --results_file results.csv
```

This will go through all models, compressions, and modes in one shot.

Results saved to:

```
.outputs/run_<timestamp>/
results.csv
```

---

## ğŸ“„ License

MIT License Â© 2025 **Purnendu Prabhat**

---

If you're looking for a quick and practical way to do CNN pruning for deployment â€” this is a solid place to start.